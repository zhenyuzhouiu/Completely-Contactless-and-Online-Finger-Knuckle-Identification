\section{Experiments and Results}
For proving TRTL loss function performance, we will compare its performance with Soft-Shift Triplet (STTL)\cite{liu2020contactless} loss function on different public finger knuckle database based on the RFNet \cite{liu2020contactless}. With TRTL loss function, the RFNet is represented by RFNet-TRTL, on the country, RFNet-STTL represents with STTL loss function. Compare to convolution layer or dilated convolution \cite{yu2015multi}, the deformable convolution \cite{zhu2019deformable} can solve local deformable by sampling different location and different weight. We also replace the RFNet convolution layer with deformable convolution layer called DeConvRFNet. As for the RFNet and DeConvRFNet, we will firstly pretrain on the HK PolyU Finger Knuckle Images Database (V1.0) \cite{fingerknuckledbv1.0} as the pretrained weights.

Meanwhile, we will also compare with the FKNet \cite{cheng2020deep} which get the state-of-the-art performance on 3D finger knuckle identification, and EfficientNetV2-S \cite{tan2021efficientnetv2}. Both of FKNet and EfficientNetV2-S are classification neural network. As a classification neural network, it commonly has a problem when the number of classes of testing dataset is not as same as the training set classes, result in fine-tuning on the testing set. Therefore, we use the vector before soft-max layer as the feature vector, and then calculate the MSE of two feature vectors as the similarity score during matching finger knuckle. We use the ResNet-50 pretrained weights as the FKNet initial weights, and use the pretrained weights on the ImageNet21K as the initial weights of EfficientNetV2-S.

In generally, public finger knuckle database already offer segmented finger knuckle images, but we use the 

In this section, all experiment will use the finger knuckle segmented by YOLOv5-CSL as the input image to train all models and test the matching performance. 

EfficientNetV2-S is the original classification model, we keep the same architecture and just change the FC layer of the head part with convolution layer for fitting TRTL and STTL to compose EfficientNetV2-S-STTL and EfficientNetV2-S-TRTL model. When trained these EfficientNetV2-S model, we use the pretrained weight on the ImageNet21K. As for the FKNet, we use the pretrained ResNet-50 weights.

\subsection{Model Complexity Analysis}

\begin{table}[H]
    \centering
    \begin{tabular}{c c c c c c}
        \hline
        Model & \makecell[c]{Prams \\(M)} & \makecell[c]{Input Size} & \makecell[c]{FLOPs \\(B)} & \makecell[c]{Feature \\Extraction \\ (s)} & \makecell[c]{Matching \\ (s)} \\
        \hline
        DeConvRFNet-STTL & 0.36M &128x128 &1.29B  &  &  \\
        DeConvRFNet-TRTL & 0.36M &128x128 &1.29B  &  & \\
        EfficientNetV2-S \cite{tan2021efficientnetv2} & 20.18M &300x300 & 5.40B &  & \\
        EfficientNetV2-S-STTL & 20.00M &300x300 & 5.38B &  &  \\
        EfficientNetV2-S-TRTL &20.00M &300x300 & 5.38B &  & \\
        FKNet \cite{cheng2020deep} &7.28M &96x64 & 0.28B &   &  \\
        RFNet-STTL \cite{liu2020contactless} & 0.46M &128x128 & 1.39B & 0.0062s & 0.049s \\
        RFNet-TRTL & 0.46M &128x128 & 1.39B & 0.0062s & \\
        \hline
    \end{tabular}
    \caption{Model complexity analysis}
    \label{model-complexity}
\end{table}

.........