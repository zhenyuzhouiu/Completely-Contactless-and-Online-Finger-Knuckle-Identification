\section{Conclusions and Future Work}

The generalization performance of convolutional neural networks is extremely powerful, and the features extracted by the convolutional kernel are so robust, for example with scale invariance, that neural networks have started to replace traditional feature description operators. However, neural networks do not have capabilities such as rotation invariance and translation invariance \cite{jaderberg2015spatial}. In practical application scenarios, contactless finger knuckle recognition system, are most susceptible to problems such as interference from complex backgrounds, and affine transformation such as rotation or translation of finger knuckle. Therefore, we propose the RSIL loss for increase the neural network rotating and shifting invariance performance. From the within database and cross database matching performance on the experiment section, it shows that with our RSIL loss, RFNet-RSIL can outperform state-of-the-art on the listed public finger knuckle database. We have also based the YOLOv5 model to resolve the interference of complex backgrounds and to obtain angular information to further mitigate the rotation problem. In Section 5, YOLOv5x-CSL can get a high mAP value on finger knuckle detection, and using it for segmenting finger knuckle can improve the matching accuracy.

Since we have design a completely contactless and online finger knuckle identification system, but we still have to solve several limitations. The first problem is the amount of data. For practical applications in various industries, the current amount of data on the finger knuckle is too sparse to allow the model to be adequately trained, unlike face recognition and fingerprint recognition which have such a large amount of data. To further improve performance is to increase the amount of data on the finger knuckle. Not only are the finger knuckle prone to rotation and translation, but an even greater headache is the problem of deformation, which occurs even in 3D space. In the deformable finger knuckle database \cite{fingerknuckledbv3.0}, our method performance not very good. This is because the finger knuckle are partially flexible. Even though I used deformable convolution, it did not improve the matching performance. We think a future direction could deal with chunked feature maps or first extracting key points, such as ending points or bifurcation, and then getting a local match based on the location of these key points. Another problem is that our current approach is two-stage, where a network is trained to detect the position of the finger knuckle in order to segment. Then, another network is used to extract the finger knuckle features for matching. In fact, the finger knuckle features are already extracted during finger knuckle detection, therefore, why not use it to indirectly match the finger knuckle as an end-to-end model. Or do multitask model instead of such a tedious process.
